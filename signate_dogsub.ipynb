{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "signate_dogsub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uqKc90ZIfBDPoJD2DO7ZuhUlaHqUlDd6",
      "authorship_tag": "ABX9TyMYix7J4a4jr0zH2FN8yO8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radperia/SIGNATE_student_2020/blob/master/signate_dogsub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMmtY385K9Q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca2dedd-f822-4e05-9604-21f64c352824"
      },
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 / 60 / 60 \"h)\"}'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.161704days (3.8809h)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5-CRHkHMrpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de51ae13-be31-4a80-91db-19778213efe3"
      },
      "source": [
        "!git clone https://github.com/microsoft/LightGBM"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7f9VKHtMyFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b387f610-50ef-454e-b819-f87df05889a8"
      },
      "source": [
        "!cd LightGBM && mkdir build && cd build && cmake .. && make -j\"$(nproc)\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L14fQTELM3z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "415b7fd3-92f5-436f-e771-eff46e6a6b45"
      },
      "source": [
        "!cd LightGBM/python-package && python setup.py install --precompile"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "running egg_info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "running install_lib\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "running install_egg_info\n",
            "removing '/usr/local/lib/python3.6/dist-packages/lightgbm-3.0.0-py3.6.egg-info' (and everything under it)\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-3.0.0-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqrk_rsgsrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from contextlib import contextmanager\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import time\n",
        "import re\n",
        "import string\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import gc\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import psutil\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQvkeVGODve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "4fee07c6-6cad-417e-ef94-5d5260416f19"
      },
      "source": [
        "train_df = pd.read_csv('./drive/My Drive/SIGNATE/train.csv').fillna(' ')\n",
        "test_df  = pd.read_csv('./drive/My Drive/SIGNATE/test.csv').fillna(' ')\n",
        "sample = pd.read_csv('./drive/My Drive/SIGNATE/submit_sample.csv', header=None)\n",
        "\n",
        "train_text = train_df['description']\n",
        "test_text = test_df['description']\n",
        "all_text = pd.concat([train_text, test_text])\n",
        "\n",
        "sentences = train_df['description'].tolist() + test_df['description'].tolist()\n",
        "sentences[::500]  # 500個飛ばしに確認"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Executes and writes portions of testing plans, protocols, and documentation for assigned portion of application; identifies and debugs issues with code and suggests changes or improvements.',\n",
              " 'Knowledge and experience of complex software design for distributed systems in embedded networking/telecommunications projects.',\n",
              " 'Analyze client business processes of storing and managing data.',\n",
              " 'Defining tasks, timeline and required resources to deliver on the mechanical design portion of a project brief, with strong accountability for successful completion of agreed upon deliverables.',\n",
              " 'Familiar with sensors, transducers, physiologic modeling, and transfer functions',\n",
              " 'Manage, maintain, refresh and upgrade environmental components (including patching, etc.)',\n",
              " 'Conduct research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence',\n",
              " 'Assist in planning and development of visualizations and analytic aggregations to best portray discovered insights, optimizing utility to the customer.',\n",
              " 'Working with vendors to troubleshoot the platform and issues related to integrations with other internal systems',\n",
              " 'Be a servant leader by providing technical guidance, DevOps mentorship and bridging silos between teams']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA7mq_sfgjZr",
        "colab_type": "text"
      },
      "source": [
        "tfidfの文献があったからやってみる https://www.kaggle.com/ogrellier/lgbm-with-words-and-chars-n-gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evXzsmV7Mn8O",
        "colab_type": "text"
      },
      "source": [
        "ここから　https://www.kaggle.com/peterhurford/lightgbm-with-select-k-best-on-tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRf6vc2fDgHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "\n",
        "calc_f1 = lambda y, p: metrics.f1_score(y, p.argmax(axis=1), average='macro')\n",
        "\n",
        "def macro_f1(pred: np.array, data: lgb.Dataset):\n",
        "    y = data.get_label()\n",
        "    pred = pred.reshape(-1, len(y)).T  # -> (N, num_class)\n",
        "\n",
        "    f1 = calc_f1(y, pred)\n",
        "    return 'macro_f1', f1, True  # True means \"higher is better\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzCK3HTaDAZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_params={\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'custom',\n",
        "    'num_class': 4,\n",
        "    'num_iterations': 2000,\n",
        "    'learning_rate': 0.0001,\n",
        "    'max_depth': -1,\n",
        "    'num_leaves': 15,\n",
        "    'max_bin': 40,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'nthread': -1,\n",
        "    'bagging_freq': 1,\n",
        "    'verbose': -1,\n",
        "    'seed': 42,\n",
        "}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxV3PutTf1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dog_params = {\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'custom',\n",
        "    'num_class': 4,\n",
        "    'learning_rate': 0.01,\n",
        "    'max_depth': -1,\n",
        "    'num_leaves': 15,\n",
        "    'max_bin': 31,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'nthread': -1,\n",
        "    'bagging_freq': 1,\n",
        "    'verbose': -1,\n",
        "    'seed': 1,\n",
        "    }"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz51L6_FOW5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d2ea7ea-35bb-4342-87d5-0ce77354ab53"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000)  # 出現頻度上位{num_words}だけを用いる\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "print(list(tokenizer.word_index)[:10] ) # 学習された辞書（出現頻度順）"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'to', 'the', 'of', 'with', 'data', 'in', 'for', 'a', 'business']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esc5Arh5OY2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91349fc5-cdb0-49f3-a92b-502cc5f61940"
      },
      "source": [
        "# 学習・検証に分けて，ベクトルを生成。加えて，正解ラベルも作成\n",
        "train_X, test_X = np.split(tokenizer.texts_to_matrix(sentences, mode='binary'),\n",
        "                           [len(train_df)], axis=0)\n",
        "\n",
        "train_y = train_df['jobflag'].values - 1  # maps {1, 2, 3 ,4} -> {0, 1, 2, 3}\n",
        "train_X.shape, train_y.shape, test_X.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2931, 1000), (2931,), (1743, 1000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFdr0zKVOe3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65741c60-d6c9-4229-f79b-6bf3592143d0"
      },
      "source": [
        "weight = 1 / pd.DataFrame(train_y).reset_index().groupby(0).count().values\n",
        "weight = weight[train_y].ravel()\n",
        "weight /= weight.sum()\n",
        "\n",
        "print(weight)\n",
        "\n",
        "dtrain = lgb.Dataset(train_X, train_y, weight=weight)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00071839 0.00018169 0.00042882 ... 0.00040064 0.00018169 0.00071839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8kaxOWx_q8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cfac1b2-823a-4d47-be59-536a117935f3"
      },
      "source": [
        "import collections\n",
        "print(collections.Counter(train_df['jobflag']))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 1376, 1: 624, 4: 583, 2: 348})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkSoA2JKNgd",
        "colab_type": "text"
      },
      "source": [
        "SVCでの最適化、class_weightでクラス間の重み変えてるつもりだけどどうも違うっぽい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdmr8FaAT8jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ccc0f9df-24d6-4e4b-c325-ba5e6fec2f0c"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "def param():\n",
        "  tuned_parameters = {\n",
        "      'C': [0.1, 1, 10],\n",
        "      'kernel':['rbf', 'linear', 'poly'],\n",
        "      'gamma': ['auto'],\n",
        "      'class_weight': ['balanced']\n",
        "  }\n",
        "  return tuned_parameters\n",
        "\n",
        "score = 'f1'\n",
        "\n",
        "svc_cv = GridSearchCV(SVC(), param(), n_jobs=-1, cv=5, verbose=3, scoring='%s_weighted'%score)\n",
        "'''\n",
        "svc_cv.fit(train_X, train_y)\n",
        "\n",
        "svc_result = pd.DataFrame.from_dict(svc_cv.cv_results_)\n",
        "svc_result.to_csv('svc_result.csv')\n",
        "'''"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nsvc_cv.fit(train_X, train_y)\\n\\nsvc_result = pd.DataFrame.from_dict(svc_cv.cv_results_)\\nsvc_result.to_csv('svc_result.csv')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_nTDKk7ldu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best = svc_cv.best_estimator_\n",
        "#pred = best.predict(test_X)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39XFhyTP9-bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "6764dcda-2502-48cd-ccd4-9c007eff4a2a"
      },
      "source": [
        "print(pred.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-289d49315128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd1wkwaFIbp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pred + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhh_p1YZ8DhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = sample\n",
        "sub[1] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whk6v-Yi88k4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "pd.DataFrame(sub, index=test_df.index).to_csv('adjusted_svc.csv', header=None)\n",
        "files.download('adjusted_svc.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qVPCD0Urxg",
        "colab_type": "text"
      },
      "source": [
        "SVCやったし、RFCもやりたい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6LVLJnUumR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nearly 6 hours\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "rfc_param = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [10, 30, 50],\n",
        "    'min_samples_leaf': [2, 4, 6],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'bootstrap': ['True'],\n",
        "    'class_weight': ['balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc_cv = GridSearchCV(estimator=rfc, param_grid=rfc_param, cv=5, verbose=3, n_jobs=-1, scoring='%s_weighted'%'f1')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtpJEJoL89OO",
        "colab_type": "text"
      },
      "source": [
        "流石に通り数が多すぎた 13500で450minかかる  \n",
        "750/45 で0.39台"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du9sLPv2eJ4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "277f9e76-5bb8-4371-b811-8d48a3d35d9c"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [\n",
        "              ('rfc', rfc_cv),\n",
        "              ('svc', svc_cv)\n",
        "]\n",
        "\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000))\n",
        "clf_stack.fit(train_X, train_y)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   26.4s\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  6.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  5.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   41.3s\n",
            "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   40.7s\n",
            "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.4s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   41.1s\n",
            "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   41.5s\n",
            "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    8.7s\n",
            "[Parallel(n_jobs=-1)]: Done 222 tasks      | elapsed:   41.5s\n",
            "[Parallel(n_jobs=-1)]: Done 382 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 894 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=None,\n",
              "                   estimators=[('rfc',\n",
              "                                GridSearchCV(cv=5, error_score=nan,\n",
              "                                             estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                                              ccp_alpha=0.0,\n",
              "                                                                              class_weight=None,\n",
              "                                                                              criterion='gini',\n",
              "                                                                              max_depth=None,\n",
              "                                                                              max_features='auto',\n",
              "                                                                              max_leaf_nodes=None,\n",
              "                                                                              max_samples=None,\n",
              "                                                                              min_impurity_decrease=0.0,\n",
              "                                                                              min_impurity_split=None,\n",
              "                                                                              min_samples_leaf=1,\n",
              "                                                                              min_samples_split=2,\n",
              "                                                                              min_weight_f...\n",
              "                                             return_train_score=False,\n",
              "                                             scoring='f1_weighted',\n",
              "                                             verbose=3))],\n",
              "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=1000,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='lbfgs',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8w6nj8dCeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55f1d3ff-41b6-499c-90d6-97ad88c746a6"
      },
      "source": [
        "clf_stack.get_params()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cv': None, 'estimators': [('rfc', GridSearchCV(cv=5, error_score=nan,\n",
              "                estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                                 class_weight=None,\n",
              "                                                 criterion='gini', max_depth=None,\n",
              "                                                 max_features='auto',\n",
              "                                                 max_leaf_nodes=None,\n",
              "                                                 max_samples=None,\n",
              "                                                 min_impurity_decrease=0.0,\n",
              "                                                 min_impurity_split=None,\n",
              "                                                 min_samples_leaf=1,\n",
              "                                                 min_samples_split=2,\n",
              "                                                 min_weight_fraction_leaf=0.0,\n",
              "                                                 n_estimators=100, n_jobs=None,...\n",
              "                                                 warm_start=False),\n",
              "                iid='deprecated', n_jobs=-1,\n",
              "                param_grid={'bootstrap': ['True'],\n",
              "                            'class_weight': ['balanced', 'balanced_subsample'],\n",
              "                            'max_depth': [10, 30, 50],\n",
              "                            'max_features': ['auto', 'sqrt'],\n",
              "                            'min_samples_leaf': [2, 4, 6],\n",
              "                            'min_samples_split': [2, 5],\n",
              "                            'n_estimators': [10, 50, 100]},\n",
              "                pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "                scoring='f1_weighted', verbose=3)),\n",
              "  ('svc', GridSearchCV(cv=5, error_score=nan,\n",
              "                estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                              class_weight=None, coef0=0.0,\n",
              "                              decision_function_shape='ovr', degree=3,\n",
              "                              gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                              probability=False, random_state=None, shrinking=True,\n",
              "                              tol=0.001, verbose=False),\n",
              "                iid='deprecated', n_jobs=-1,\n",
              "                param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],\n",
              "                            'gamma': ['auto'],\n",
              "                            'kernel': ['rbf', 'linear', 'poly']},\n",
              "                pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "                scoring='f1_weighted', verbose=3))], 'final_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                    warm_start=False), 'final_estimator__C': 1.0, 'final_estimator__class_weight': None, 'final_estimator__dual': False, 'final_estimator__fit_intercept': True, 'final_estimator__intercept_scaling': 1, 'final_estimator__l1_ratio': None, 'final_estimator__max_iter': 1000, 'final_estimator__multi_class': 'auto', 'final_estimator__n_jobs': None, 'final_estimator__penalty': 'l2', 'final_estimator__random_state': None, 'final_estimator__solver': 'lbfgs', 'final_estimator__tol': 0.0001, 'final_estimator__verbose': 0, 'final_estimator__warm_start': False, 'n_jobs': None, 'passthrough': False, 'rfc': GridSearchCV(cv=5, error_score=nan,\n",
              "              estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                               class_weight=None,\n",
              "                                               criterion='gini', max_depth=None,\n",
              "                                               max_features='auto',\n",
              "                                               max_leaf_nodes=None,\n",
              "                                               max_samples=None,\n",
              "                                               min_impurity_decrease=0.0,\n",
              "                                               min_impurity_split=None,\n",
              "                                               min_samples_leaf=1,\n",
              "                                               min_samples_split=2,\n",
              "                                               min_weight_fraction_leaf=0.0,\n",
              "                                               n_estimators=100, n_jobs=None,...\n",
              "                                               warm_start=False),\n",
              "              iid='deprecated', n_jobs=-1,\n",
              "              param_grid={'bootstrap': ['True'],\n",
              "                          'class_weight': ['balanced', 'balanced_subsample'],\n",
              "                          'max_depth': [10, 30, 50],\n",
              "                          'max_features': ['auto', 'sqrt'],\n",
              "                          'min_samples_leaf': [2, 4, 6],\n",
              "                          'min_samples_split': [2, 5],\n",
              "                          'n_estimators': [10, 50, 100]},\n",
              "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "              scoring='f1_weighted', verbose=3), 'rfc__cv': 5, 'rfc__error_score': nan, 'rfc__estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                        criterion='gini', max_depth=None, max_features='auto',\n",
              "                        max_leaf_nodes=None, max_samples=None,\n",
              "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                        min_samples_leaf=1, min_samples_split=2,\n",
              "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                        n_jobs=None, oob_score=False, random_state=None,\n",
              "                        verbose=0, warm_start=False), 'rfc__estimator__bootstrap': True, 'rfc__estimator__ccp_alpha': 0.0, 'rfc__estimator__class_weight': None, 'rfc__estimator__criterion': 'gini', 'rfc__estimator__max_depth': None, 'rfc__estimator__max_features': 'auto', 'rfc__estimator__max_leaf_nodes': None, 'rfc__estimator__max_samples': None, 'rfc__estimator__min_impurity_decrease': 0.0, 'rfc__estimator__min_impurity_split': None, 'rfc__estimator__min_samples_leaf': 1, 'rfc__estimator__min_samples_split': 2, 'rfc__estimator__min_weight_fraction_leaf': 0.0, 'rfc__estimator__n_estimators': 100, 'rfc__estimator__n_jobs': None, 'rfc__estimator__oob_score': False, 'rfc__estimator__random_state': None, 'rfc__estimator__verbose': 0, 'rfc__estimator__warm_start': False, 'rfc__iid': 'deprecated', 'rfc__n_jobs': -1, 'rfc__param_grid': {'bootstrap': ['True'],\n",
              "  'class_weight': ['balanced', 'balanced_subsample'],\n",
              "  'max_depth': [10, 30, 50],\n",
              "  'max_features': ['auto', 'sqrt'],\n",
              "  'min_samples_leaf': [2, 4, 6],\n",
              "  'min_samples_split': [2, 5],\n",
              "  'n_estimators': [10,\n",
              "   50,\n",
              "   100]}, 'rfc__pre_dispatch': '2*n_jobs', 'rfc__refit': True, 'rfc__return_train_score': False, 'rfc__scoring': 'f1_weighted', 'rfc__verbose': 3, 'stack_method': 'auto', 'svc': GridSearchCV(cv=5, error_score=nan,\n",
              "              estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                            class_weight=None, coef0=0.0,\n",
              "                            decision_function_shape='ovr', degree=3,\n",
              "                            gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                            probability=False, random_state=None, shrinking=True,\n",
              "                            tol=0.001, verbose=False),\n",
              "              iid='deprecated', n_jobs=-1,\n",
              "              param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],\n",
              "                          'gamma': ['auto'],\n",
              "                          'kernel': ['rbf', 'linear', 'poly']},\n",
              "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "              scoring='f1_weighted', verbose=3), 'svc__cv': 5, 'svc__error_score': nan, 'svc__estimator': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "     tol=0.001, verbose=False), 'svc__estimator__C': 1.0, 'svc__estimator__break_ties': False, 'svc__estimator__cache_size': 200, 'svc__estimator__class_weight': None, 'svc__estimator__coef0': 0.0, 'svc__estimator__decision_function_shape': 'ovr', 'svc__estimator__degree': 3, 'svc__estimator__gamma': 'scale', 'svc__estimator__kernel': 'rbf', 'svc__estimator__max_iter': -1, 'svc__estimator__probability': False, 'svc__estimator__random_state': None, 'svc__estimator__shrinking': True, 'svc__estimator__tol': 0.001, 'svc__estimator__verbose': False, 'svc__iid': 'deprecated', 'svc__n_jobs': -1, 'svc__param_grid': {'C': [0.1,\n",
              "   1,\n",
              "   10],\n",
              "  'class_weight': ['balanced'],\n",
              "  'gamma': ['auto'],\n",
              "  'kernel': ['rbf',\n",
              "   'linear',\n",
              "   'poly']}, 'svc__pre_dispatch': '2*n_jobs', 'svc__refit': True, 'svc__return_train_score': False, 'svc__scoring': 'f1_weighted', 'svc__verbose': 3, 'verbose': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHn0xAI0coW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ca51a73-9fdf-4e4f-9b42-79d3aba5f476"
      },
      "source": [
        "clf_stack.score(train_X, train_y)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7932446264073695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XVpyajskR0k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bc7b7e93-81a3-4023-a7c4-57a91629dd5c"
      },
      "source": [
        "stacking_pred = clf_stack.predict(test_X)\n",
        "stacking_pred = stacking_pred + 1\n",
        "stacking_sub = sample\n",
        "stacking_sub[1] = stacking_pred\n",
        "\n",
        "from google.colab import files\n",
        "pd.DataFrame(stacking_sub, index=test_df.index).to_csv('stacking_clf_0.7932.csv', header=None)\n",
        "files.download('stacking_clf_0.7932.csv')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_96aa8e7f-fdb9-4f87-9da0-90ac7a480e48\", \"stacking_clf_0.7932.csv\", 19806)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDba1boUN70j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvbooster = lgb.cv(my_params, dtrain, return_cvbooster=True, stratified=False, \n",
        "        num_boost_round=9999, verbose_eval=100, early_stopping_rounds=500,\n",
        "        feval=macro_f1)['cvbooster']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTXkUKPvvK-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('./drive/My Drive/SIGNATE/train.csv', index_col=0)\n",
        "test_df  = pd.read_csv('./drive/My Drive/SIGNATE/test.csv',  index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RgPpTYBOhYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.stack(cvbooster.predict(test_X)).mean(axis=0).argmax(axis=1) + 1\n",
        "pd.DataFrame(pred, index=test_df.index).to_csv('./myversion_dog_lgb814.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nne15MqxN_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('myversion_dog_lgb814.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}