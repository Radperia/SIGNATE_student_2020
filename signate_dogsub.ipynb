{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "signate_dogsub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uqKc90ZIfBDPoJD2DO7ZuhUlaHqUlDd6",
      "authorship_tag": "ABX9TyMBjA57EzuNEzA7gcac/c/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radperia/SIGNATE_student_2020/blob/master/signate_dogsub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMmtY385K9Q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b108f4db-908f-493f-f139-791acfdb253e"
      },
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 / 60 / 60 \"h)\"}'"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.211335days (5.07203h)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5-CRHkHMrpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c452e41e-6570-45f5-88b4-db399c068994"
      },
      "source": [
        "!git clone https://github.com/microsoft/LightGBM"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7f9VKHtMyFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "563ec772-7ab5-4553-e272-8a72a5805251"
      },
      "source": [
        "!cd LightGBM && mkdir build && cd build && cmake .. && make -j\"$(nproc)\""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘build’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L14fQTELM3z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "0cf7b321-c656-4c58-c70b-c8cfb37ff6f2"
      },
      "source": [
        "!cd LightGBM/python-package && python setup.py install --precompile"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "running egg_info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "running install_lib\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "running install_egg_info\n",
            "removing '/usr/local/lib/python3.6/dist-packages/lightgbm-3.0.0-py3.6.egg-info' (and everything under it)\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-3.0.0-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqrk_rsgsrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from contextlib import contextmanager\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import time\n",
        "import re\n",
        "import string\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import gc\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import psutil\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQvkeVGODve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "8afd70ce-804a-432a-eadb-f7c4c9eb51bb"
      },
      "source": [
        "train_df = pd.read_csv('./drive/My Drive/SIGNATE/train.csv').fillna(' ')\n",
        "test_df  = pd.read_csv('./drive/My Drive/SIGNATE/test.csv').fillna(' ')\n",
        "sample = pd.read_csv('./drive/My Drive/SIGNATE/submit_sample.csv', header=None)\n",
        "\n",
        "train_text = train_df['description']\n",
        "test_text = test_df['description']\n",
        "all_text = pd.concat([train_text, test_text])\n",
        "\n",
        "sentences = train_df['description'].tolist() + test_df['description'].tolist()\n",
        "sentences[::500]  # 500個飛ばしに確認"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Executes and writes portions of testing plans, protocols, and documentation for assigned portion of application; identifies and debugs issues with code and suggests changes or improvements.',\n",
              " 'Knowledge and experience of complex software design for distributed systems in embedded networking/telecommunications projects.',\n",
              " 'Analyze client business processes of storing and managing data.',\n",
              " 'Defining tasks, timeline and required resources to deliver on the mechanical design portion of a project brief, with strong accountability for successful completion of agreed upon deliverables.',\n",
              " 'Familiar with sensors, transducers, physiologic modeling, and transfer functions',\n",
              " 'Manage, maintain, refresh and upgrade environmental components (including patching, etc.)',\n",
              " 'Conduct research on cutting-edge techniques and tools in machine learning/deep learning/artificial intelligence',\n",
              " 'Assist in planning and development of visualizations and analytic aggregations to best portray discovered insights, optimizing utility to the customer.',\n",
              " 'Working with vendors to troubleshoot the platform and issues related to integrations with other internal systems',\n",
              " 'Be a servant leader by providing technical guidance, DevOps mentorship and bridging silos between teams']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA7mq_sfgjZr",
        "colab_type": "text"
      },
      "source": [
        "tfidfの文献があったからやってみる https://www.kaggle.com/ogrellier/lgbm-with-words-and-chars-n-gram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evXzsmV7Mn8O",
        "colab_type": "text"
      },
      "source": [
        "ここから　https://www.kaggle.com/peterhurford/lightgbm-with-select-k-best-on-tfidf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRf6vc2fDgHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn import metrics\n",
        "\n",
        "calc_f1 = lambda y, p: metrics.f1_score(y, p.argmax(axis=1), average='macro')\n",
        "\n",
        "def macro_f1(pred: np.array, data: lgb.Dataset):\n",
        "    y = data.get_label()\n",
        "    pred = pred.reshape(-1, len(y)).T  # -> (N, num_class)\n",
        "\n",
        "    f1 = calc_f1(y, pred)\n",
        "    return 'macro_f1', f1, True  # True means \"higher is better\""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzCK3HTaDAZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_params={\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'custom',\n",
        "    'num_class': 4,\n",
        "    'num_iterations': 2000,\n",
        "    'learning_rate': 0.0001,\n",
        "    'max_depth': -1,\n",
        "    'num_leaves': 15,\n",
        "    'max_bin': 40,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'nthread': -1,\n",
        "    'bagging_freq': 1,\n",
        "    'verbose': -1,\n",
        "    'seed': 42,\n",
        "}"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxV3PutTf1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dog_params = {\n",
        "    'objective': 'multiclass',\n",
        "    'metric': 'custom',\n",
        "    'num_class': 4,\n",
        "    'learning_rate': 0.01,\n",
        "    'max_depth': -1,\n",
        "    'num_leaves': 15,\n",
        "    'max_bin': 31,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'nthread': -1,\n",
        "    'bagging_freq': 1,\n",
        "    'verbose': -1,\n",
        "    'seed': 1,\n",
        "    }"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz51L6_FOW5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba8d96c2-d887-4876-a91e-44839ea8e2e9"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=1000)  # 出現頻度上位{num_words}だけを用いる\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "print(list(tokenizer.word_index)[:10] ) # 学習された辞書（出現頻度順）"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'to', 'the', 'of', 'with', 'data', 'in', 'for', 'a', 'business']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esc5Arh5OY2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5dec783-b7ce-4aab-b5cb-8ba762511d9b"
      },
      "source": [
        "# 学習・検証に分けて，ベクトルを生成。加えて，正解ラベルも作成\n",
        "train_X, test_X = np.split(tokenizer.texts_to_matrix(sentences, mode='binary'),\n",
        "                           [len(train_df)], axis=0)\n",
        "\n",
        "train_y = train_df['jobflag'].values - 1  # maps {1, 2, 3 ,4} -> {0, 1, 2, 3}\n",
        "train_X.shape, train_y.shape, test_X.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2931, 1000), (2931,), (1743, 1000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFdr0zKVOe3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34fa41b8-25e5-4444-e1dc-79866f720621"
      },
      "source": [
        "weight = 1 / pd.DataFrame(train_y).reset_index().groupby(0).count().values\n",
        "weight = weight[train_y].ravel()\n",
        "weight /= weight.sum()\n",
        "\n",
        "print(weight)\n",
        "\n",
        "dtrain = lgb.Dataset(train_X, train_y, weight=weight)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00071839 0.00018169 0.00042882 ... 0.00040064 0.00018169 0.00071839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8kaxOWx_q8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d7c0c74-0c96-4d8f-c8a7-c72e4c15aa0e"
      },
      "source": [
        "import collections\n",
        "print(collections.Counter(train_df['jobflag']))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 1376, 1: 624, 4: 583, 2: 348})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZkSoA2JKNgd",
        "colab_type": "text"
      },
      "source": [
        "SVCでの最適化、class_weightでクラス間の重み変えてるつもりだけどどうも違うっぽい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdmr8FaAT8jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "218c1009-6d5d-459f-85be-109d7d093ce7"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import SVC\n",
        "def param():\n",
        "  tuned_parameters = {\n",
        "      'C': [0.1, 1, 10],\n",
        "      'kernel':['rbf', 'linear', 'poly'],\n",
        "      'gamma': ['auto'],\n",
        "      'class_weight': ['balanced']\n",
        "  }\n",
        "  return tuned_parameters\n",
        "\n",
        "score = 'f1'\n",
        "\n",
        "svc_cv = GridSearchCV(SVC(), param(), n_jobs=-1, cv=5, verbose=3, scoring='%s_weighted'%score)\n",
        "'''\n",
        "svc_cv.fit(train_X, train_y)\n",
        "\n",
        "svc_result = pd.DataFrame.from_dict(svc_cv.cv_results_)\n",
        "svc_result.to_csv('svc_result.csv')\n",
        "'''"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nsvc_cv.fit(train_X, train_y)\\n\\nsvc_result = pd.DataFrame.from_dict(svc_cv.cv_results_)\\nsvc_result.to_csv('svc_result.csv')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_nTDKk7ldu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#best = svc_cv.best_estimator_\n",
        "#pred = best.predict(test_X)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39XFhyTP9-bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "16388dd8-a298-4911-921d-36303b188727"
      },
      "source": [
        "print(pred.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-289d49315128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd1wkwaFIbp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pred + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhh_p1YZ8DhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = sample\n",
        "sub[1] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whk6v-Yi88k4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "pd.DataFrame(sub, index=test_df.index).to_csv('adjusted_svc.csv', header=None)\n",
        "files.download('adjusted_svc.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9qVPCD0Urxg",
        "colab_type": "text"
      },
      "source": [
        "SVCやったし、RFCもやりたい"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6LVLJnUumR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nearly 6 hours\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "rfc_param = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'max_depth': [10, 30, 50],\n",
        "    'min_samples_leaf': [2, 6, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'bootstrap': ['True'],\n",
        "    'class_weight': ['balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc_cv = GridSearchCV(estimator=rfc, param_grid=rfc_param, cv=5, verbose=3, n_jobs=-1, scoring='%s_weighted'%'f1')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtpJEJoL89OO",
        "colab_type": "text"
      },
      "source": [
        "流石に通り数が多すぎた 13500で450minかかる  \n",
        "750/45 で0.39台"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du9sLPv2eJ4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a2fed83-d26c-4db2-a1ce-c4fe8a782270"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [\n",
        "              ('rfc', rfc_cv),\n",
        "              ('svc', svc_cv)\n",
        "]\n",
        "\n",
        "clf_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000))\n",
        "clf_stack.fit(train_X, train_y)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   32.2s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 10.0min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 27.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 37.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 50.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 67.8min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 70.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  5.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   29.4s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 22.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 30.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 40.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 53.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 56.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   26.2s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 29.4min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 39.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 53.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 56.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   27.5s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 22.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 41.3min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 55.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 57.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   27.7s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 22.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 41.4min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 55.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 58.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   27.5s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 22.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed: 40.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 55.3min\n",
            "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 57.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=None,\n",
              "                   estimators=[('rfc',\n",
              "                                GridSearchCV(cv=5, error_score=nan,\n",
              "                                             estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                                              ccp_alpha=0.0,\n",
              "                                                                              class_weight=None,\n",
              "                                                                              criterion='gini',\n",
              "                                                                              max_depth=None,\n",
              "                                                                              max_features='auto',\n",
              "                                                                              max_leaf_nodes=None,\n",
              "                                                                              max_samples=None,\n",
              "                                                                              min_impurity_decrease=0.0,\n",
              "                                                                              min_impurity_split=None,\n",
              "                                                                              min_samples_leaf=1,\n",
              "                                                                              min_samples_split=2,\n",
              "                                                                              min_weight_f...\n",
              "                                             return_train_score=False,\n",
              "                                             scoring='f1_weighted',\n",
              "                                             verbose=3))],\n",
              "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                      dual=False,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      intercept_scaling=1,\n",
              "                                                      l1_ratio=None,\n",
              "                                                      max_iter=1000,\n",
              "                                                      multi_class='auto',\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      random_state=None,\n",
              "                                                      solver='lbfgs',\n",
              "                                                      tol=0.0001, verbose=0,\n",
              "                                                      warm_start=False),\n",
              "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
              "                   verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8w6nj8dCeT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0d829787-46aa-4388-ae5c-573491d295d7"
      },
      "source": [
        "clf_stack.get_params()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c08ab3850b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'clf_stack' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHn0xAI0coW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_stack.score(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XVpyajskR0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacking_pred = clf_stack.predict(test_X)\n",
        "stacking_pred = stacking_pred + 1\n",
        "stacking_sub = sample\n",
        "stacking_sub[1] = stacking_pred\n",
        "\n",
        "from google.colab import files\n",
        "pd.DataFrame(stacking_sub, index=test_df.index).to_csv('stacking_clf_0.7932.csv', header=None)\n",
        "files.download('stacking_clf_0.7932.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDba1boUN70j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvbooster = lgb.cv(my_params, dtrain, return_cvbooster=True, stratified=False, \n",
        "        num_boost_round=9999, verbose_eval=100, early_stopping_rounds=500,\n",
        "        feval=macro_f1)['cvbooster']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTXkUKPvvK-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('./drive/My Drive/SIGNATE/train.csv', index_col=0)\n",
        "test_df  = pd.read_csv('./drive/My Drive/SIGNATE/test.csv',  index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RgPpTYBOhYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.stack(cvbooster.predict(test_X)).mean(axis=0).argmax(axis=1) + 1\n",
        "pd.DataFrame(pred, index=test_df.index).to_csv('./myversion_dog_lgb814.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nne15MqxN_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('myversion_dog_lgb814.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}